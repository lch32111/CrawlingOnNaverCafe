* 설치
1) Python 3.0 이상 다운로드
2) pip를 이용한 selenium 설치 (pip install -U selenium)
3) pip를 이용한 BeautifulSoup 설치 (pip install beautifulsoup4)
4) 크롬 설정 -> 크롬 정보 -> 버전 확인 -> http://chromedriver.chromium.org/downloads
    -> 링크를 통해 크롬버전에 맞는 드라이버 다운로드
5) 드라이버 .exe 파일 위치 경로 txt 파일에 적을것
    예시) E:\MyDownLoad\chromedriver.exe

* 프로그램 사용
1. 네이버 ID/PW 입력
2. 입력 후 크롬 브라우저가 실행 후 네이버 로그인
3. 크롬 브라우저가 카페 섹션으로 이동
4. Python Idle에 가입 카페 목록 리스트 출력
5. 카페 목록 번호 입력하여 해당 카페로 이동
6. Python Idle에 카페 메뉴 출력
7. (반복) 카페 메뉴, 페이지 시작과 끝을 입력하여 크롤링 데이터 수집

* 크롤링 데이터 형식
1) 파일명 : 저장 시간 / 카페 이름 / 카페 메뉴 / 시작페이지 - 끝페이지
2) 파일 내용 형식: 
- 파일의 맨 위에 기록 시간, 카페이름, 메뉴가 기록된다.
	Time : # (기록된 시간)
	Cafe : # (카페 이름) / # (카페 링크)
	Menu : # (카페 메뉴) / # (카페 메뉴 링크)

- 한 게시글의 내용은 [ ] 안에 기록이 된다.
	[
		Page : #
		제목 : # 
		내용 : #
		댓글 : #
		링크 : # (게시글 링크)
	]


* 한계점 : 빠르게 대충 하드코딩했기 때문에 많은 단점들이 있음.
- 잘못된 인덱스 등에 대해 에러 탐지 및 복구 X
- 일반적인 형식이 아닌 카페 / 게시판에 대해 처리 X
- 컴퓨터가 느려서 load 속도가 느릴 시에 대한 처리 X
- 설치를 직접 다 해주어야 함
- 크롬 드라이버 경로를 잘 설정해주어야함
- 프로그램 실행 시 마다 ID/PW 매번 입력해야함
- 한 번 카페에 가면 다른 카페로 갈 수 없음 
  (즉, 다른 카페를 가려면 종료 후 다시 시작)
- 카페 메뉴는 한 번만 출력 되어 
  필요한 카페 메뉴 인덱스를 알아야 함
- 크롤링 데이터는 카페메뉴/페이지시작/끝을 입력할 때 마다 
  분리되어서 txt파일로 저장됨